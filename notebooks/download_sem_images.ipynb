{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ef35dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import gc\n",
    "import requests\n",
    "import random\n",
    "import lxml\n",
    "from IPython.display import clear_output\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60eb33d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "UserAgent = [\n",
    "        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\"\n",
    "        ]\n",
    "\n",
    "\n",
    "def requestHeader(url):\n",
    "    # Build request headers\n",
    "    headers = {\n",
    "            'User-Agent':random.choice(UserAgent),\n",
    "            'Referer': url,\n",
    "            'Connection':'keep-alive'\n",
    "            }\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37254666",
   "metadata": {},
   "source": [
    "Elsevier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1635653",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_df = pd.read_csv('../data/231217_works.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce13ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../secret/elsevier_api.txt') as f:\n",
    "    api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98997b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result_df_array = []\n",
    "count = 0\n",
    "for doi in works_df['doi'].values[max_index:]:\n",
    "    url = 'https://api.elsevier.com/content/article/doi/' + doi + '?APIKey=' + api_key + '&view=FULL'\n",
    "    try:\n",
    "        response = requests.get(url, headers= requestHeader(url))\n",
    "        \n",
    "        file = BeautifulSoup(response.text, \"lxml\")\n",
    "        \n",
    "        #jpeg_objects = file.find_all('object', category='standard', multimediatype=\"JPEG image file\")\n",
    "        figure_objects = file.find_all('ce:figure')\n",
    "        \n",
    "        for figure_object in figure_objects:\n",
    "            try:\n",
    "                caption = figure_object.find('ce:caption').text.lower()\n",
    "                cond_1 = 'sem image' in caption\n",
    "                cond_2 = 'scanning electron micro' in caption\n",
    "                cond_3 = 'sem micro' in caption\n",
    "                cond_4 = 'sem pic' in caption\n",
    "                if (cond_1 | cond_2 | cond_3 | cond_4 ):\n",
    "                    print('SEM figure identified.')\n",
    "                    locator_str = figure_object.find('ce:link')['locator']\n",
    "                    figure_types = file.find_all('object',\n",
    "                                            ref=locator_str)\n",
    "                    for figure_type in figure_types:\n",
    "                        figure_link = figure_type.text\n",
    "                        figure_name = figure_link.split('?')[0].split('/')[-1]\n",
    "                        if figure_name[-3:] == 'jpg':\n",
    "                            figure_link = figure_link.split('?')[0] + '?APIKey=' + api_key\n",
    "                            img_response = requests.get(figure_link, headers= requestHeader(url))\n",
    "                            with open('../img/' + figure_name, 'wb') as f:\n",
    "                                f.write(img_response.content)\n",
    "                            result_df_array.append(pd.DataFrame({'doi':[doi], \n",
    "                                                                 'locator':[locator_str], \n",
    "                                                                 'caption':[caption], \n",
    "                                                                 'filename':[figure_name]}))\n",
    "            except:\n",
    "                print('Figure does not have caption.')\n",
    "    except:\n",
    "        print('Error reading DOI: ' + doi)\n",
    "            \n",
    "    file.decompose()\n",
    "        \n",
    "    count += 1\n",
    "    print(str(count) + ' DOIs processed.')\n",
    "\n",
    "    if count % 1000 == 0:\n",
    "        gc.collect()\n",
    "        result_df = pd.concat(result_df_array)\n",
    "        result_df.to_csv('../data/sem_images_231217_batch_count_' + str(count) + '_.csv', index=False)\n",
    "        result_df_array = []\n",
    "        clear_output()\n",
    "\n",
    "result_df = pd.concat(result_df_array)\n",
    "result_df.to_csv('../data/sem_images_231217_batch_count_' + str(count) + '_.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2be639",
   "metadata": {},
   "source": [
    "PLOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319bddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout_errors = []\n",
    "\n",
    "result_df_array = []\n",
    "count = 0\n",
    "doi_list = works_df['doi'].values[max_index:]\n",
    "\n",
    "for doi in doi_list:\n",
    "    n_complete = len(result_df_array)\n",
    "    url = 'https://doi.org/' + doi\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers= requestHeader(url))\n",
    "        \n",
    "        file = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "        figure_objects = file.find_all('div', {'class':'figure'})\n",
    "    except:\n",
    "        with open('../data/timeout.txt', 'a+') as f:\n",
    "            f.write(doi)\n",
    "        figure_objects = []\n",
    "    \n",
    "    for figure_object in figure_objects:\n",
    "        try:\n",
    "            if 'Table' not in figure_object.find('div', {'class':'figcaption'}).text:\n",
    "                caption = ''\n",
    "                for obj in figure_object.find('div', {'class':'figcaption'}):\n",
    "                    caption += obj.text\n",
    "                for obj in figure_object.find_all('p'):\n",
    "                    caption += ' ' + obj.text\n",
    "                caption = figure_object.text.lower()\n",
    "\n",
    "                cond_1 = 'sem image' in caption\n",
    "                cond_2 = 'scanning electron micro' in caption\n",
    "                cond_3 = 'sem micro' in caption\n",
    "                cond_4 = 'sem pic' in caption\n",
    "                if (cond_1 | cond_2 | cond_3 | cond_4 ):\n",
    "                    print('SEM figure identified.')\n",
    "                    #fig_link figure_object.find_all('li')[1].find('a')['href']\n",
    "                    locator_str = figure_object['data-doi'].split('.')[-1]\n",
    "                    \n",
    "                    href = ''\n",
    "                    fig_link = ''\n",
    "                    for image_object in figure_object.find_all('li'):\n",
    "                        if 'larger image' == image_object.find('div', {'class':'definition-description'}).text:\n",
    "                            href = image_object.find('a')['href']\n",
    "                            fig_link = 'https://journals.plos.org/plosone/' + href\n",
    "                    img_response = requests.get(fig_link, headers= requestHeader(url))\n",
    "                    \n",
    "                    with open('../img/' + fig_link.split('/')[-1] + '.png', 'wb') as f:\n",
    "                        f.write(img_response.content)\n",
    "\n",
    "                    result_df_array.append(pd.DataFrame({'doi':[doi], \n",
    "                                                      'locator':[locator_str], \n",
    "                                                      'caption':[caption], \n",
    "                                                      'filename':[fig_link.split('/')[-1]  + '.png']}))\n",
    "                \n",
    "        except:\n",
    "            print('Error processing figure')\n",
    "        \n",
    "    count += 1\n",
    "    print(str(count) + ' DOIs processed.')\n",
    "    file.decompose()\n",
    "    \n",
    "    if count % 1000 == 0:\n",
    "        try:\n",
    "            gc.collect()\n",
    "            result_df = pd.concat(result_df_array)\n",
    "            result_df.to_csv('../data/sem_images_240118_batch_count_' + str(count) + '_.csv', index=False)\n",
    "            result_df_array = []\n",
    "        except:\n",
    "            print('No objects to concatenate.')\n",
    "        clear_output()\n",
    "        \n",
    "    if count % 10 == 0:\n",
    "        clear_output()\n",
    "        gc.collect()\n",
    "\n",
    "result_df = pd.concat(result_df_array)\n",
    "result_df.to_csv('../data/sem_images_240118_batch_count_' + str(count) + '_.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7412d197",
   "metadata": {},
   "source": [
    "Frontiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d484d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dcaf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_array = []\n",
    "count = 0\n",
    "doi_list = works_df['doi'].values\n",
    "\n",
    "for doi in doi_list[max_index:]:\n",
    "    n_complete = len(result_df_array)\n",
    "    url = 'https://doi.org/' + doi\n",
    "    \n",
    "    time.sleep(1)\n",
    "    response = requests.get(url, headers= requestHeader(url))\n",
    "    \n",
    "    file = BeautifulSoup(response.text, \"lxml\")\n",
    "    \n",
    "    figure_objects = file.find_all('div', {'class':'FigureDesc'})\n",
    "    \n",
    "    for figure_object in figure_objects:\n",
    "        try:\n",
    "            caption = figure_object.text.lower()\n",
    "            locator_str = figure_object.find('a')['name']\n",
    "            fig_cond = 'Figure' in locator_str\n",
    "            cond_1 = 'sem image' in caption\n",
    "            cond_2 = 'scanning electron micro' in caption\n",
    "            cond_3 = 'sem micro' in caption\n",
    "            cond_4 = 'sem pic' in caption\n",
    "            if ((cond_1 | cond_2 | cond_3 | cond_4 ) & fig_cond):\n",
    "                print('SEM figure identified.')\n",
    "                fig_link = figure_object.find('a')['href']\n",
    "                img_response = requests.get(fig_link, headers= requestHeader(url))\n",
    "                filename = fig_link.split('/')[-1]\n",
    "                with open('../img/' + filename, 'wb') as f:\n",
    "                    f.write(img_response.content)\n",
    "                result_df_array.append(pd.DataFrame({'doi':[doi], \n",
    "                                                     'locator':[locator_str], \n",
    "                                                     'caption':[caption], \n",
    "                                                     'filename':[filename]}))\n",
    "        except:\n",
    "            print('Error processing figure.')\n",
    "    file.decompose()\n",
    "    \n",
    "    count += 1\n",
    "    print(str(count) + ' DOIs processed.')\n",
    "    \n",
    "    if (count % 1000 == 0) & (len(result_df_array) > 0):\n",
    "        gc.collect()\n",
    "        result_df = pd.concat(result_df_array)\n",
    "        result_df.to_csv('../data/sem_images_240104_batch_count_' + str(count) + '_.csv', index=False)\n",
    "        result_df_array = []\n",
    "        clear_output()\n",
    "        \n",
    "    if count % 10 == 0:\n",
    "        clear_output()\n",
    "        gc.collect()\n",
    "\n",
    "result_df = pd.concat(result_df_array)\n",
    "result_df.to_csv('../data/sem_images_240104_batch_count_' + str(count) + '_.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c7be4",
   "metadata": {},
   "source": [
    "Nature Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a494ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_array = []\n",
    "count = 0\n",
    "doi_list = works_df['doi'].values\n",
    "\n",
    "for doi in doi_list:\n",
    "    n_complete = len(result_df_array)\n",
    "    url = 'https://doi.org/' + doi\n",
    "    \n",
    "    time.sleep(1)\n",
    "    response = requests.get(url, headers= requestHeader(url))\n",
    "    \n",
    "    file = BeautifulSoup(response.text, \"lxml\")\n",
    "    \n",
    "    figure_objects = file.find_all('div', {'class':'c-article-section__figure-description'})\n",
    "    \n",
    "    for figure_object in figure_objects:\n",
    "        try:\n",
    "            caption = figure_object.text.lower()\n",
    "            cond_1 = 'sem image' in caption\n",
    "            cond_2 = 'scanning electron micro' in caption\n",
    "            cond_3 = 'sem micro' in caption\n",
    "            cond_4 = 'sem pic' in caption\n",
    "            if (cond_1 | cond_2 | cond_3 | cond_4 ):\n",
    "                print('SEM figure identified.')\n",
    "                locator_str = figure_object['id']\n",
    "                #print(locator_str)\n",
    "                figure_number = locator_str.split('-')[1]\n",
    "                fig_link = 'https://www.nature.com' + file.find('a', {'aria-label':'Full size image figure ' + figure_number})['href']\n",
    "                \n",
    "                time.sleep(1)\n",
    "                response = requests.get(fig_link, headers= requestHeader(url))\n",
    "                figure_page_file = BeautifulSoup(response.text, \"lxml\")\n",
    "                \n",
    "                time.sleep(1)\n",
    "                fig_src_url = 'https:' + figure_page_file.find_all('picture')[-1].find('img')['src']\n",
    "                img_response = requests.get(fig_src_url, headers= requestHeader(url))\n",
    "                with open('../img/' + fig_src_url.split('/')[-1], 'wb') as f:\n",
    "                    f.write(img_response.content)\n",
    "                result_df_array.append(pd.DataFrame({'doi':[doi], \n",
    "                                                     'locator':[locator_str], \n",
    "                                                     'caption':[caption], \n",
    "                                                     'filename':[fig_src_url.split('/')[-1]]}))\n",
    "                \n",
    "        except:\n",
    "            print('Error processing figure')\n",
    "        \n",
    "    count += 1\n",
    "    print(str(count) + ' DOIs processed.')\n",
    "    file.decompose()\n",
    "    \n",
    "    if count % 1000 == 0:\n",
    "        gc.collect()\n",
    "        result_df = pd.concat(result_df_array)\n",
    "        result_df.to_csv('../data/sem_images_231227_batch_count_' + str(count) + '_.csv', index=False)\n",
    "        result_df_array = []\n",
    "        clear_output()\n",
    "        \n",
    "    if count % 10 == 0:\n",
    "        clear_output()\n",
    "        gc.collect()\n",
    "\n",
    "result_df = pd.concat(result_df_array)\n",
    "result_df.to_csv('../data/sem_images_231227_batch_count_' + str(count) + '_.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
